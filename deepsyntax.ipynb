{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4ayKhlXAbZS"
      },
      "outputs": [],
      "source": [
        "!pip install torch transformers datasets scikit-learn matplotlib seaborn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"Sp1786/multiclass-sentiment-analysis-dataset\")\n"
      ],
      "metadata": {
        "id": "JFwMec0zAnKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset)\n"
      ],
      "metadata": {
        "id": "KT_0VaXyAwWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset[\"train\"][0:5])\n"
      ],
      "metadata": {
        "id": "m49YgWQDAzhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train size:\", len(dataset[\"train\"]))\n",
        "print(\"Test size:\", len(dataset[\"test\"]))\n"
      ],
      "metadata": {
        "id": "WBsaK6dRA3b5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = dataset[\"train\"][\"label\"]\n",
        "print(set(labels))\n"
      ],
      "metadata": {
        "id": "XsWq-V-QA6UC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "\n",
        "label_counts = Counter(labels)\n",
        "\n",
        "plt.figure()\n",
        "sns.barplot(x=list(label_counts.keys()), y=list(label_counts.values()))\n",
        "plt.title(\"Class Distribution\")\n",
        "plt.xlabel(\"Label\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "9wb-xtXVA9Nk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the class distribution plot, we observe that some sentiment classes have more samples than others. The dataset is slightly imbalanced but not extremely skewed"
      ],
      "metadata": {
        "id": "TZEmairSA_Ij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels=len(set(labels))\n",
        ")\n"
      ],
      "metadata": {
        "id": "H1gGyQPqBEyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(example):\n",
        "    return tokenizer(\n",
        "        example[\"text\"],   # this will now be a list when batched=True\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=128\n",
        "    )\n"
      ],
      "metadata": {
        "id": "mMYj63PzBe-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(example):\n",
        "    # Replace None or non-string values with empty string\n",
        "    texts = [\n",
        "        str(t) if t is not None else \"\"\n",
        "        for t in example[\"text\"]\n",
        "    ]\n",
        "\n",
        "    return tokenizer(\n",
        "        texts,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=128\n",
        "    )\n"
      ],
      "metadata": {
        "id": "n8CK76OSB-m3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.map(tokenize_function, batched=True)\n"
      ],
      "metadata": {
        "id": "i13-2PMyCoTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.remove_columns([\"id\", \"text\", \"sentiment\"])\n"
      ],
      "metadata": {
        "id": "othohRi7Crvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.set_format(\"torch\")\n"
      ],
      "metadata": {
        "id": "DKtiEpYBCtxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset[\"train\"][0])\n"
      ],
      "metadata": {
        "id": "BvUHp85xCwA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(dataset[\"train\"], batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(dataset[\"test\"], batch_size=16)\n"
      ],
      "metadata": {
        "id": "goau-iTKC7UR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "import torch\n",
        "\n",
        "num_labels = len(set(dataset[\"train\"][\"label\"]))\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels=num_labels\n",
        ")\n"
      ],
      "metadata": {
        "id": "VibLbmfIC89k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "print(\"Using device:\", device)\n"
      ],
      "metadata": {
        "id": "hhWblayhDPW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n"
      ],
      "metadata": {
        "id": "9fnhwxrXD5mt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 2\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"label\"].to(device)\n",
        "\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            labels=labels\n",
        "        )\n",
        "\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch+1} Loss: {avg_loss}\")\n"
      ],
      "metadata": {
        "id": "PHvFxkkaD7cy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "model.eval()\n",
        "\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"label\"].to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(all_labels, all_preds))\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(all_labels, all_preds))\n"
      ],
      "metadata": {
        "id": "009JnuWxKbLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GYmnHejbKqsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the confusion matrix, we observe that most predictions lie on the diagonal, indicating correct classifications. Some misclassification occurs between class 0 and class 1, which may be due to similarity in sentiment"
      ],
      "metadata": {
        "id": "VE7tTcEwK6yI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "original_dataset = load_dataset(\"Sp1786/multiclass-sentiment-analysis-dataset\")\n",
        "\n",
        "label_names = {}\n",
        "\n",
        "for example in original_dataset[\"train\"]:\n",
        "    label_names[example[\"label\"]] = example[\"sentiment\"]\n",
        "\n",
        "print(label_names)\n"
      ],
      "metadata": {
        "id": "hQHEIo0bLYud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def predict_text(text: str):\n",
        "    model.eval()\n",
        "\n",
        "    inputs = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=128\n",
        "    )\n",
        "\n",
        "    input_ids = inputs[\"input_ids\"].to(device)\n",
        "    attention_mask = inputs[\"attention_mask\"].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        probs = F.softmax(outputs.logits, dim=1)\n",
        "        confidence, predicted_class = torch.max(probs, dim=1)\n",
        "\n",
        "    label = predicted_class.item()\n",
        "\n",
        "    return {\n",
        "        \"Predicted Label\": label_names[label],\n",
        "        \"Confidence\": float(confidence.item())\n",
        "    }\n"
      ],
      "metadata": {
        "id": "RUbpU8qWLckv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_text(\"I absolutely loved this movie!\")\n",
        "predict_text(\"This was the worst product ever.\")\n",
        "predict_text(\"It was fine, nothing special.\")\n"
      ],
      "metadata": {
        "id": "quNqTEK7LefF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"sentiment_model\")\n",
        "tokenizer.save_pretrained(\"sentiment_model\")\n"
      ],
      "metadata": {
        "id": "N33wRUZ9LvGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this assignment, we fine-tuned a pre-trained BERT-base-uncased model for multiclass sentiment classification using PyTorch.\n",
        "The model achieved an accuracy of approximately 76â€“77% on the test set.\n",
        "The results demonstrate the effectiveness of transfer learning for text classification tasks"
      ],
      "metadata": {
        "id": "kA2Ji47YLzcj"
      }
    }
  ]
}